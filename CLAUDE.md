# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Commands

```bash
# Activate venv (required for all commands)
source .venv/bin/activate

# Start server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
# or: ./start.sh

# Run all engine tests
pytest tests/test_engine.py -v

# Run a single test by name
pytest tests/test_engine.py -v -k "test_pasta_with_chicken"

# Run normalization tests
pytest tests/test_normalization.py tests/test_normalization_e2e.py -v

# Run all tests
pytest tests/ -v

# Ingest course material into ChromaDB (only needed after content changes)
python scripts/ingest.py

# Parse recipe markdown → recipes.json
python scripts/parse_recipes.py
```

## Architecture

### Request Flow (multi-file)

A chat request flows through these files in order:

1. **`app/main.py`** — receives `POST /chat` or `POST /chat/image`, calls `handle_chat()`
2. **`app/chat_service.py`** — orchestrates the full pipeline:
   - `normalize_input()` — typo fixes, EN→DE translation, time standardization
   - calls `vision_service.py` if image attached
   - calls `chat_modes.py` to detect `ChatMode`
   - calls `trennkost/analyzer.py` if food query
   - calls `recipe_service.py` if recipe request
   - RAG retrieval via ChromaDB
   - calls `prompt_builder.py` to assemble the final prompt
   - OpenAI call → save to SQLite via `database.py`
3. **`app/chat_modes.py`** — returns `(ChatMode, ChatModifiers)`. Modes: `KNOWLEDGE`, `FOOD_ANALYSIS`, `MENU_ANALYSIS`, `MENU_FOLLOWUP`, `RECIPE_REQUEST`
4. **`app/prompt_builder.py`** — contains `SYSTEM_INSTRUCTIONS` (14 critical rules) and per-mode prompt builders. The system instructions are the single source of truth for LLM behavior.
5. **`trennkost/analyzer.py`** — top-level entry: calls normalizer, engine, formats results for LLM via `format_results_for_llm()`
6. **`trennkost/engine.py`** — pure deterministic evaluation, no LLM calls, reads rules from `trennkost/data/rules.json`

### Trennkost Engine (immutable rule)

**LLM is never used for Trennkost verdicts.** Only for extraction and explanation. The engine in `trennkost/engine.py` evaluates food groups against `rules.json` deterministically. The LLM in `prompt_builder.py` only explains the pre-computed verdict.

Chain: `trennkost/analyzer.py` → `trennkost/normalizer.py` (extract items) → `trennkost/ontology.py` (lookup groups) → `trennkost/engine.py` (apply rules) → `format_results_for_llm()` → injected into prompt

### Data files
- `trennkost/data/ontology.csv` — ~300 food items, human-editable, bilingual DE+EN
- `trennkost/data/rules.json` — 20+ rules, each with `condition`, `verdict`, `severity`
- `trennkost/data/compounds.json` — known compound dishes (e.g., "Kartoffelsalat")
- `app/data/recipes.json` — 86 curated recipes (generated by `scripts/parse_recipes.py`)

### Frontend
Single-file SPA: `app/main_frontend.html` (73 KB). All CSS and JS are embedded. Served directly by FastAPI at `GET /`.

### Storage layout
```
storage/
  chroma/        # ChromaDB vector DB (course snippets)
  chat.db        # SQLite (conversations + messages)
  uploads/       # Temporary image uploads (auto-cleaned after 24h)
  feedback/      # Exported feedback submissions
```

## Adding Ontology Entries

Edit `trennkost/data/ontology.csv` directly. Columns: `canonical, synonyms, group, subgroup, ambiguity_flag, ambiguity_note, high_fat, notes`. Groups: `OBST, TROCKENOBST, NEUTRAL, KH, HUELSENFRUECHTE, PROTEIN, MILCH, FETT, UNKNOWN`. After editing, re-run `pytest tests/test_engine.py -v` to catch regressions.

## Adding / Modifying Rules

Edit `trennkost/data/rules.json`. Each rule needs: `rule_id`, `description`, `condition` (with `pair` or `group_present`), `verdict` (`OK|NOT_OK|CONDITIONAL`), `severity` (`CRITICAL|WARNING|INFO`), `source_ref`, `explanation`. Run engine tests after changes.

## Key Constraints

- **No LLM verdicts**: `trennkost/engine.py` must never call OpenAI. All verdict logic is in `rules.json`.
- **Normalization safety**: `normalize_input()` in `chat_service.py` skips messages >200 chars and preserves short follow-ups (<5 words with context) to avoid over-expansion.
- **Vision anti-hallucination**: `vision_service.py` explicitly ignores Gewürze, Zusatzstoffe, E-Nummern — only visible ingredients.
- **FALLBACK_SENTENCE** in `prompt_builder.py` is the canonical "not in course material" response — keep it consistent.
